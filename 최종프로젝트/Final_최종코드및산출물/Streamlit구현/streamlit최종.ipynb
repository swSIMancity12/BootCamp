{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ë°ì´í„° ìˆ˜ì§‘ ìë™í™”"
      ],
      "metadata": {
        "id": "C9pzCEBfjN0M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuZHesF9jLF3"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import yfinance as yf\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fredapi import Fred\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "import itertools\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "import plotly.graph_objects as go\n",
        "from collections import Counter\n",
        "import collections\n",
        "from st_on_hover_tabs import on_hover_tabs\n",
        "\n",
        "## ë°ì´í„°ìˆ˜ì§‘\n",
        "start_date = '20190101'\n",
        "\n",
        "# í•œêµ­ì€í–‰ api\n",
        "def fetch_data(stat_code, cycle, item_code1, item_code2, start_date= start_date):\n",
        "    # ì˜¤ëŠ˜ ë‚ ì§œ êµ¬í•˜ê¸° (YYYYMMDD í˜•ì‹)\n",
        "    today_date = datetime.today().strftime('%Y%m%d')\n",
        "\n",
        "    # í˜¸ì¶œ url ì‘ì„±\n",
        "    url = f'http://ecos.bok.or.kr/api/StatisticSearch/P4JHAI59YVHQEHBFFOTX/json/kr/1/10000/{stat_code}/{cycle}/{start_date}/{today_date}/{item_code1}/{item_code2}/'\n",
        "\n",
        "    # ìš”ì²­í•˜ê³  ìë™ ì‘ë‹µì„ ë°›ëŠ”ë° í•„ìš”í•œ í•¨ìˆ˜ í˜¸ì¶œ\n",
        "    response = requests.get(url)\n",
        "    data = response.text\n",
        "\n",
        "    # json-> dictìë£Œí˜•\n",
        "    api_dict = json.loads(data)\n",
        "\n",
        "    mid = api_dict['StatisticSearch']['row']\n",
        "\n",
        "    # ë°ì´í„° ì¶”ì¶œ\n",
        "    extracted_data = [{'DATE': item['TIME'], item['ITEM_NAME1']: item['DATA_VALUE']} for item in mid]\n",
        "\n",
        "    # ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
        "    df = pd.DataFrame(data=extracted_data)\n",
        "\n",
        "    # 'DATE' ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì…ì„ datetime64[ns]ë¡œ ë³€í™˜\n",
        "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# í™˜ìœ¨\n",
        "df_usd_krw = fetch_data('731Y001', 'D', '0000001', 'ì› ')\n",
        "\n",
        "# EUR/KRW\n",
        "jisu_start_date = datetime.strptime(start_date, '%Y%m%d').strftime('%Y-%m-%d')\n",
        "jisu_today_date= datetime.today().strftime('%Y-%m-%d')\n",
        "ticker_symbol_eur_krw = 'EURKRW=X'\n",
        "eur_krw_data = yf.download(ticker_symbol_eur_krw, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_eur_krw = pd.DataFrame({'DATE':eur_krw_data.index, 'EUR_KRW':eur_krw_data.values})\n",
        "\n",
        "# GBP/KRW\n",
        "ticker_symbol_gbp_krw = 'GBPKRW=X'\n",
        "gbp_krw_data = yf.download(ticker_symbol_gbp_krw, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_gbp_krw = pd.DataFrame({'DATE':gbp_krw_data.index, 'GBP_KRW':gbp_krw_data.values})\n",
        "\n",
        "# JPY/KRW\n",
        "ticker_symbol_jpy_krw = 'JPYKRW=X'\n",
        "jpy_krw_data = yf.download(ticker_symbol_jpy_krw, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_jpy_krw = pd.DataFrame({'DATE':jpy_krw_data.index, 'JPY_KRW':jpy_krw_data.values})\n",
        "\n",
        "# EUR/USD\n",
        "ticker_symbol_eur_usd = 'EURUSD=X'\n",
        "eur_usd_data = yf.download(ticker_symbol_eur_usd, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_eur_usd = pd.DataFrame({'DATE':eur_usd_data.index, 'EUR_USD':eur_usd_data.values})\n",
        "\n",
        "# GBP/USD\n",
        "ticker_symbol_gbp_usd = 'GBPUSD=X'\n",
        "gbp_usd_data = yf.download(ticker_symbol_gbp_usd, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_gbp_usd = pd.DataFrame({'DATE':gbp_usd_data.index, 'GBP_USD':gbp_usd_data.values})\n",
        "\n",
        "# JPY/USD\n",
        "ticker_symbol_jpy = 'JPYUSD=X'\n",
        "jpy_data = yf.download(ticker_symbol_jpy, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_jpy = pd.DataFrame({'DATE':jpy_data.index, 'JPY_USD':jpy_data.values})\n",
        "\n",
        "# ì½”ìŠ¤í”¼\n",
        "df_kospi = fetch_data('802Y001', 'D', '0001000', '')\n",
        "\n",
        "# ë‹¤ìš°ì¡´ìŠ¤ ì§€ìˆ˜\n",
        "ticker_symbol_djia = '^DJI'\n",
        "djia_data = yf.download(ticker_symbol_djia, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_djia = pd.DataFrame({'DATE': djia_data.index, 'ë‹¤ìš°ì¡´ìŠ¤': djia_data.values})\n",
        "\n",
        "# S&P500\n",
        "ticker_symbol_sp500 = '^GSPC'\n",
        "sp500_data = yf.download(ticker_symbol_sp500, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_sp500 = pd.DataFrame({'DATE': sp500_data.index, 'S&P500': sp500_data.values})\n",
        "\n",
        "# ë‚˜ìŠ¤ë‹¥ ì§€ìˆ˜\n",
        "ticker_symbol_nasdaq = '^IXIC'\n",
        "nasdaq_data = yf.download(ticker_symbol_nasdaq, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_nasdaq = pd.DataFrame({'DATE': nasdaq_data.index, 'ë‚˜ìŠ¤ë‹¥': nasdaq_data.values})\n",
        "\n",
        "# FTSE 100\n",
        "ticker_symbol_ftse = '^FTSE'\n",
        "ftse_data = yf.download(ticker_symbol_ftse, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_ftse = pd.DataFrame({'DATE': ftse_data.index, 'FTSE': ftse_data.values})\n",
        "\n",
        "# DAX\n",
        "ticker_symbol_dax = '^GDAXI'\n",
        "dax_data = yf.download(ticker_symbol_dax, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_dax = pd.DataFrame({'DATE': dax_data.index, 'DAX': dax_data.values})\n",
        "\n",
        "# CAC\n",
        "ticker_symbol_cac = 'CAC'\n",
        "cac_data = yf.download(ticker_symbol_cac, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_cac = pd.DataFrame({'DATE': cac_data.index, 'CAC': cac_data.values})\n",
        "\n",
        "# Nikkei\n",
        "start_date = '2019/01/01'\n",
        "fred = Fred(api_key='6abc0a218c6e24d76c4cc78c070e4a16')\n",
        "data_nikkei = fred.get_series('NIKKEI225',observation_start = start_date)\n",
        "df_Nikkei = pd.DataFrame({'DATE': data_nikkei.index, 'Nikkei': data_nikkei.values})\n",
        "\n",
        "# ë¯¸êµ­ë‹¬ëŸ¬ì§€ìˆ˜\n",
        "ticker_symbol_dxy = 'DX-Y.NYB'\n",
        "dxy_data = yf.download(ticker_symbol_dxy, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_dxy = pd.DataFrame({'DATE': dxy_data.index, 'ë¯¸êµ­ë‹¬ëŸ¬ì§€ìˆ˜': dxy_data.values})\n",
        "\n",
        "# 6ê°œì›”\n",
        "data_6M = fred.get_series('DGS6MO',observation_start = start_date)\n",
        "df_6M = pd.DataFrame({'DATE': data_6M.index, 'ë¯¸êµ­êµ­ì±„ê¸ˆë¦¬6ê°œì›”': data_6M.values})\n",
        "\n",
        "# 1ë…„\n",
        "data_1 = fred.get_series('DGS1',observation_start = start_date)\n",
        "df_1 = pd.DataFrame({'DATE': data_1.index, 'ë¯¸êµ­êµ­ì±„ê¸ˆë¦¬1ë…„': data_1.values})\n",
        "\n",
        "# 3ë…„\n",
        "data_3 = fred.get_series('DGS3',observation_start = start_date)\n",
        "df_3 = pd.DataFrame({'DATE': data_3.index, 'ë¯¸êµ­êµ­ì±„ê¸ˆë¦¬3ë…„': data_3.values})\n",
        "\n",
        "# 5ë…„\n",
        "data_5 = fred.get_series('DGS5',observation_start = start_date)\n",
        "df_5 = pd.DataFrame({'DATE': data_5.index, 'ë¯¸êµ­êµ­ì±„ê¸ˆë¦¬5ë…„': data_5.values})\n",
        "\n",
        "# 10ë…„\n",
        "data_10 = fred.get_series('DGS10',observation_start = start_date)\n",
        "df_10 = pd.DataFrame({'DATE': data_10.index, 'ë¯¸êµ­êµ­ì±„ê¸ˆë¦¬10ë…„': data_10.values})\n",
        "\n",
        "# ê¸ˆ\n",
        "ticker_symbol_gold = 'GC=F'\n",
        "gold_data = yf.download(ticker_symbol_gold, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_gold = pd.DataFrame({'DATE': gold_data.index, 'ê¸ˆ': gold_data.values})\n",
        "\n",
        "# ì€\n",
        "ticker_symbol_silver = 'SI=F'\n",
        "silver_data = yf.download(ticker_symbol_silver, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_silver = pd.DataFrame({'DATE': silver_data.index, 'ì€': silver_data.values})\n",
        "\n",
        "# WTI ì›ìœ  ê°€ê²©\n",
        "data_wti = fred.get_series('DCOILWTICO',observation_start = start_date)\n",
        "df_wti = pd.DataFrame({'DATE': data_wti.index, 'WTI': data_wti.values})\n",
        "\n",
        "# ì²œì—°ê°€ìŠ¤\n",
        "ticker_symbol_gas = 'NG=F'\n",
        "gas_data = yf.download(ticker_symbol_gas, start=jisu_start_date, end=jisu_today_date)['Close']\n",
        "df_gas = pd.DataFrame({'DATE': gas_data.index, 'ì²œì—°ê°€ìŠ¤': gas_data.values})\n",
        "\n",
        "# ì›ë³¸ ë°ì´í„°í”„ë ˆì„ë“¤\n",
        "dfs = [df_usd_krw, df_eur_krw, df_gbp_krw, df_jpy_krw, df_eur_usd,df_gbp_usd,df_jpy, df_djia, df_sp500, df_nasdaq, df_ftse, df_dax, df_cac,df_Nikkei, df_dxy, df_6M, df_1, df_3, df_5, df_10,df_gold, df_silver, df_gas, df_wti, df_kospi]\n",
        "\n",
        "# ë°ì´í„°í”„ë ˆì„ ë³‘í•©\n",
        "df_combined_D = dfs[0]\n",
        "for df in dfs[1:]:\n",
        "    df_combined_D = pd.merge(df_combined_D, df, on='DATE', how='left')\n",
        "\n",
        "# ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "df_combined_D.sort_values(by='DATE', inplace=True)\n",
        "\n",
        "# nanê°’ ì±„ìš°ê¸°\n",
        "df_combined_D.fillna(method='ffill',inplace = True)\n",
        "df_combined_D.fillna(method='bfill',inplace = True)\n",
        "\n",
        "# ì»¬ëŸ¼ëª… ë°”ê¾¸ê¸°\n",
        "df = df_combined_D.rename(columns={\"DATE\":\"ë‚ ì§œ\",\"ì›/ë¯¸êµ­ë‹¬ëŸ¬(ë§¤ë§¤ê¸°ì¤€ìœ¨)\":\"í™˜ìœ¨\"})\n",
        "\n",
        "df.to_csv('ì§€ìˆ˜.csv',index=False)\n",
        "\n",
        "## ëª¨ë¸ë§\n",
        "# ë‚ ì§œ ì¹¼ëŸ¼ --> datetime í˜•íƒœë¡œ ë³€í™˜\n",
        "df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])\n",
        "\n",
        "# ë‚ ì§œ ì¹¼ëŸ¼ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •\n",
        "df.set_index('ë‚ ì§œ', inplace=True)\n",
        "\n",
        "# Feature Engineering: ì´ë™í‰ê·  ë° ê³¼ê±° í™˜ìœ¨ ê°’ ì¶”ê°€\n",
        "df['í™˜ìœ¨_7ì¼_í‰ê· '] = df['í™˜ìœ¨'].rolling(window=7).mean()\n",
        "\n",
        "for i in range(1,8):\n",
        "    df[f'í™˜ìœ¨_{i}ì¼ì „'] = df['í™˜ìœ¨'].shift(i)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# ì •ë‹µ ì»¬ëŸ¼ ìƒì„±\n",
        "df.loc[:,'target'] = df.loc[:,'í™˜ìœ¨']\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.loc[:,['target']]\n",
        "\n",
        "# ì •ê·œí™” ì§„í–‰\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_x.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# LSTM ì…ë ¥ ë°ì´í„° í˜•íƒœ ë³€í™˜\n",
        "def make_dataset(X, y, time_steps):\n",
        "    X_data_total = []\n",
        "    y_data_total = []\n",
        "    for start in np.arange(len(X)-time_steps):\n",
        "        stop = start + time_steps\n",
        "        # X_data --> ìŠ¬ë¼ì´ì‹±\n",
        "        X_data = X[start:stop, :]\n",
        "        X_data_total.append(X_data)\n",
        "        # y_data --> ì¸ë±ì‹±\n",
        "        y_data = y[stop]\n",
        "        y_data_total.append(y_data)\n",
        "    return np.array(X_data_total), np.array(y_data_total)\n",
        "\n",
        "time_steps = 30\n",
        "X_data,y_data = make_dataset(X = X_scaled, y = y_scaled, time_steps = time_steps)\n",
        "\n",
        "# í•™ìŠµìš© / í‰ê°€ìš© ë°ì´í„° ìƒì„±\n",
        "train_size = int(len(X_data) * 0.7)\n",
        "valid_size = int(len(X_data) * 0.2)\n",
        "test_size = len(X_data) - train_size - valid_size\n",
        "\n",
        "X_train = X_data[0:train_size,:,:]\n",
        "y_train = y_data[0:train_size,:]\n",
        "X_valid = X_data[train_size:train_size + valid_size,:,:]\n",
        "y_valid = y_data[train_size:train_size + valid_size,:]\n",
        "X_test = X_data[train_size + valid_size:len(X_data),:,:]\n",
        "y_test = y_data[train_size + valid_size:len(X_data),:]\n",
        "\n",
        "# ì‹œë“œ ê³ ì •\n",
        "seed = 45\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# ìµœì ì˜ íŒŒë¼ë¯¸í„°\n",
        "best_params = {'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.1, 'optimizer': 'adam', 'epochs': 20, 'regularization': 0.01}\n",
        "\n",
        "# LSTM ëª¨ë¸ ì •ì˜\n",
        "tf.keras.backend.clear_session()\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, kernel_regularizer=l2(best_params['regularization']),input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(1, kernel_regularizer=l2(best_params['regularization'])))\n",
        "\n",
        "optimizer = Adam(learning_rate=best_params['learning_rate'])\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# ì¡°ê¸° ì¢…ë£Œ ì„¤ì •\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ\n",
        "history = model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'],\n",
        "                    validation_data=(X_valid, y_valid), shuffle=False, callbacks=[early_stopping])\n",
        "\n",
        "# ì˜ˆì¸¡\n",
        "train_predict = model.predict(X_train)\n",
        "valid_predict = model.predict(X_valid)\n",
        "test_predict = model.predict(X_test)\n",
        "\n",
        "# ì˜ˆì¸¡ ê°’ ì •ê·œí™” ì´ì „ìœ¼ë¡œ ë³µì›\n",
        "train_predict = scaler_y.inverse_transform(train_predict)\n",
        "valid_predict = scaler_y.inverse_transform(valid_predict)\n",
        "test_predict = scaler_y.inverse_transform(test_predict)\n",
        "\n",
        "# ì›ë˜ ê°’ ì •ê·œí™” ì´ì „ìœ¼ë¡œ ë³µì›\n",
        "y_train_actual =  scaler_y.inverse_transform(y_train)\n",
        "y_valid_actual =  scaler_y.inverse_transform(y_valid)\n",
        "y_test_actual =  scaler_y.inverse_transform(y_test)\n",
        "\n",
        "total_predict = np.concatenate([train_predict, valid_predict, test_predict])\n",
        "total_actual = np.concatenate([y_train_actual, y_valid_actual, y_test_actual])\n",
        "\n",
        "index = df.iloc[time_steps:].index\n",
        "df_predict = pd.DataFrame(data = total_predict,index=index, columns=['ì˜ˆì¸¡í™˜ìœ¨'])\n",
        "df_predict.loc[:,'ì‹¤ì œí™˜ìœ¨'] = y.iloc[time_steps:].values.flatten()\n",
        "df_predict['ì˜ˆì¸¡í™˜ìœ¨'] = df_predict['ì˜ˆì¸¡í™˜ìœ¨'].astype(float).round(2)\n",
        "\n",
        "#ì£¼ë§ ì±„ìš°ê¸°\n",
        "date_range = pd.date_range(start=df_predict.index[0], end=df_predict.index[-1], freq='D')\n",
        "new = pd.DataFrame({'ë‚ ì§œ':date_range})\n",
        "df_predict = df_predict.reset_index()\n",
        "df_predict = pd.merge(new,df_predict, on='ë‚ ì§œ', how='left')\n",
        "df_predict.fillna(method='ffill',inplace = True)\n",
        "\n",
        "### í–¥í›„ 30ì¼ ì˜ˆì¸¡ - ì¼ë³„\n",
        "future_dates = pd.date_range(start = df.index[-1] + pd.Timedelta(days = 1), periods = 30, freq='B')\n",
        "\n",
        "future_preds = []\n",
        "input_data = np.array(X_scaled[-30:])\n",
        "\n",
        "for date in future_dates:\n",
        "    # input_dataë¥¼ ëª¨ë¸ ì…ë ¥ í˜•íƒœì— ë§ê²Œ reshape\n",
        "    input_data_reshaped = input_data.reshape(1, 30, -1)\n",
        "    pred = model.predict(input_data_reshaped)\n",
        "    future_preds.append(pred[0])\n",
        "\n",
        "    # When creating new_row, ensure all features are included\n",
        "    new_row = np.append(input_data[0, 1:], pred[0])\n",
        "    input_data = np.append(input_data[1:], new_row.reshape(1, -1), axis=0)\n",
        "\n",
        "future_preds = scaler_y.inverse_transform(np.array(future_preds).reshape(-1, 1))\n",
        "\n",
        "# ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼\n",
        "future_preds = np.round(future_preds, 2)\n",
        "\n",
        "# ë¯¸ë˜ ì˜ˆì¸¡ ë°ì´í„°í”„ë ˆì„\n",
        "future_df = pd.DataFrame({'ë‚ ì§œ': future_dates, 'ì˜ˆì¸¡í™˜ìœ¨':  future_preds.flatten()})\n",
        "\n",
        "# ì£¼ë§ í¬í•¨ - ì£¼ë§ì—ëŠ” ê¸ˆìš”ì¼ í™˜ìœ¨ë¡œ ëŒ€ì²´\n",
        "dates = pd.date_range(start = df.index[-1] + pd.Timedelta(days = 1), periods = 42, freq='D')\n",
        "new = pd.DataFrame({'ë‚ ì§œ' : dates})\n",
        "pred_dates_df = pd.merge(new, future_df, on = 'ë‚ ì§œ', how = 'left')\n",
        "pred_dates_df.fillna(method = 'ffill',inplace = True)\n",
        "\n",
        "# ì˜ˆì¸¡ í™˜ìœ¨ì˜ ì˜¤ì°¨ë²”ìœ„ ë§Œë“¤ê¸° - ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœì†Œ ì¹¼ëŸ¼, ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœëŒ€ ì¹¼ëŸ¼ ìƒì„±(ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ê¹Œì§€)\n",
        "pred_dates_df['ì˜ˆì¸¡í™˜ìœ¨'] = pred_dates_df['ì˜ˆì¸¡í™˜ìœ¨'].apply(lambda x : round(x, 2))\n",
        "pred_dates_df['ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœì†Œ'] = np.round(pred_dates_df['ì˜ˆì¸¡í™˜ìœ¨'] - 1.96*np.std(pred_dates_df['ì˜ˆì¸¡í™˜ìœ¨']), 2)\n",
        "pred_dates_df['ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœëŒ€'] = np.round(pred_dates_df['ì˜ˆì¸¡í™˜ìœ¨'] + 1.96*np.std(pred_dates_df['ì˜ˆì¸¡í™˜ìœ¨']), 2)\n",
        "\n",
        "df_end = pd.concat([df_predict,pred_dates_df[['ë‚ ì§œ','ì˜ˆì¸¡í™˜ìœ¨']]])\n",
        "\n",
        "pred_dates_df.to_csv(\"pred.csv\",index=False)\n",
        "df_end.to_csv(\"total.csv\", index = False)\n",
        "\n",
        "### 3ê°œì›” ì›”ë³„ ì˜ˆì¸¡\n",
        "future_days = 60\n",
        "future_month_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=future_days, freq='B')\n",
        "\n",
        "input_data = np.array(X_scaled[-30:])\n",
        "future_month_preds = []\n",
        "\n",
        "for date in future_month_dates:\n",
        "    input_data_reshaped = input_data.reshape(1, 30, -1)\n",
        "    pred1 = model.predict(input_data_reshaped)\n",
        "    future_month_preds.append(pred1[0])\n",
        "    new_row = np.append(input_data[0, 1:], pred1[0])\n",
        "    input_data = np.append(input_data[1:], new_row.reshape(1, -1), axis=0)\n",
        "\n",
        "future_month_preds = scaler_y.inverse_transform(np.array(future_month_preds).reshape(-1, 1))\n",
        "future_month_preds = np.round(future_month_preds, 2)\n",
        "\n",
        "# ë¯¸ë˜ ì˜ˆì¸¡ ë°ì´í„°í”„ë ˆì„\n",
        "future_month_df = pd.DataFrame({'ì˜ˆì¸¡ë‚ ì§œ': future_month_dates, 'ì˜ˆì¸¡í™˜ìœ¨': future_month_preds.flatten()})\n",
        "\n",
        "### ì£¼ë§ í¬í•¨ ë³‘í•©\n",
        "dates1 = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=future_days, freq='D')\n",
        "new1 = pd.DataFrame({'ì˜ˆì¸¡ë‚ ì§œ': dates1})\n",
        "pred_month_df = pd.merge(new1, future_month_df, on='ì˜ˆì¸¡ë‚ ì§œ', how='left')\n",
        "pred_month_df = pred_month_df.fillna(method='ffill')\n",
        "\n",
        "# ì›”ë³„ ë§ˆì§€ë§‰ ì˜ˆì¸¡í™˜ìœ¨ ê°’ ì°¾ê¸°\n",
        "pred_month_df['ì˜ˆì¸¡ë‚ ì§œ'] = pred_month_df['ì˜ˆì¸¡ë‚ ì§œ'].dt.to_period('M')\n",
        "last_day_preds = pred_month_df.groupby('ì˜ˆì¸¡ë‚ ì§œ').last().reset_index()\n",
        "last_day_preds.columns = ['ì˜ˆì¸¡ë‚ ì§œ', 'ì˜ˆì¸¡í™˜ìœ¨']\n",
        "\n",
        "# ì›”ë³„ ë§ˆì§€ë§‰ ì˜ˆì¸¡í™˜ìœ¨ ê°’ --> ì›”ë³„ ë°ì´í„°ë¡œ ë„£ê¸°(ë‚ ì§œ í˜•íƒœ ì—°ë„-ì›”)\n",
        "last_day_preds['ì˜ˆì¸¡ë‚ ì§œ'] = last_day_preds['ì˜ˆì¸¡ë‚ ì§œ'].dt.strftime('%Y-%m')\n",
        "last_day_preds['ì˜ˆì¸¡í™˜ìœ¨'] = last_day_preds['ì˜ˆì¸¡í™˜ìœ¨'].apply(lambda x: round(x, 2))\n",
        "last_day_preds['ì˜ˆì¸¡í™˜ìœ¨_ìµœì†Œ'] = np.round(last_day_preds['ì˜ˆì¸¡í™˜ìœ¨'] - 1.96 * np.std(last_day_preds['ì˜ˆì¸¡í™˜ìœ¨']), 2)\n",
        "last_day_preds['ì˜ˆì¸¡í™˜ìœ¨_ìµœëŒ€'] = np.round(last_day_preds['ì˜ˆì¸¡í™˜ìœ¨'] + 1.96 * np.std(last_day_preds['ì˜ˆì¸¡í™˜ìœ¨']), 2)\n",
        "\n",
        "last_day_preds.to_csv('í™˜ìœ¨ì˜ˆì¸¡_ì›”ë³„.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì›¹ í˜ì´ì§€"
      ],
      "metadata": {
        "id": "u2cRtR64lldz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import yfinance as yf\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fredapi import Fred\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "import itertools\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "import plotly.graph_objects as go\n",
        "from collections import Counter\n",
        "import collections\n",
        "from st_on_hover_tabs import on_hover_tabs\n",
        "from telegram import Bot\n",
        "import schedule\n",
        "import threading\n",
        "import plotly.express as px\n",
        "from streamlit_lightweight_charts import renderLightweightCharts\n",
        "\n",
        "# í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
        "st.set_page_config(page_title=\"Currency Forecast\",\n",
        "                   page_icon=\"ğŸ’µ\",\n",
        "                   layout=\"wide\")\n",
        "# CSSë¡œ ì—¬ë°± ì œê±°\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .reportview-container .main .block-container{\n",
        "        padding-top: 1rem;\n",
        "        padding-left: 1rem;\n",
        "        padding-right: 1rem;\n",
        "        padding-bottom: 1rem;\n",
        "    }\n",
        "    .centered-text {\n",
        "        text-align: center;\n",
        "    }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ì œëª©\n",
        "st.markdown(\"<h1 class='centered-text' style='font-size: 5em;'>í™˜ìœ¨ ì˜ˆì¸¡ í”„ë¡œê·¸ë¨</h1>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<h2 class='centered-text update-text' style='font-size: medium; color: gray;'>ì˜¤ì „ 9:00ì— ì—…ë°ì´íŠ¸ ë©ë‹ˆë‹¤.</h2>\", unsafe_allow_html=True)\n",
        "st.markdown('<style>' + open('./style.css').read() + '</style>', unsafe_allow_html=True)\n",
        "\n",
        "# ê·¸ë˜í”„ ì„¤ëª…\n",
        "col1, col2 = st.columns([10,0.5])\n",
        "\n",
        "with col2:\n",
        "    popover = st.popover(\":chart_with_upwards_trend:\")\n",
        "    # popover.markdown(\"**ê·¸ë˜í”„ í™•ëŒ€ ë° ì¶•ì†Œ**\")\n",
        "    multi = '''**ê·¸ë˜í”„ í™•ëŒ€ ë° ì¶•ì†Œ**\n",
        "    â–· í™•ëŒ€ : ê·¸ë˜í”„ ì˜ì—­ì„ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ ì›í•˜ëŠ” ë¶€ë¶„ì„ ì„ íƒí•˜ì„¸ìš”.\n",
        "    â–· ì¶•ì†Œ : ë”ë¸”í´ë¦­í•˜ë©´ ì›ë˜ í¬ê¸°ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.'''\n",
        "    popover.markdown(multi)\n",
        "\n",
        "\n",
        "# ì‚¬ì´ë“œ ë°”\n",
        "with st.sidebar:\n",
        "    tabs = on_hover_tabs(tabName=['Dashboard','Keyword', 'Information'],\n",
        "                         iconName=['dashboard','format_size', 'info'], default_choice=0)\n",
        "\n",
        "## í™˜ìœ¨ ë¶ˆëŸ¬ì˜¤ê¸°(ì‹œê°€,ì €ê°€,ê³ ê°€,ì¢…ê°€)\n",
        "# í•œêµ­ì€í–‰ api\n",
        "def fetch_data(stat_code, cycle, item_code1,item_code2, start_date):\n",
        "    today_date = datetime.today().strftime('%Y%m%d')\n",
        "    url = f'http://ecos.bok.or.kr/api/StatisticSearch/P4JHAI59YVHQEHBFFOTX/json/kr/1/10000/{stat_code}/{cycle}/{start_date}/{today_date}/{item_code1}/{item_code2}/'\n",
        "    response = requests.get(url)\n",
        "    data = response.text\n",
        "    api_dict = json.loads(data)\n",
        "    mid = api_dict['StatisticSearch']['row']\n",
        "    extracted_data = [{'DATE': item['TIME'], 'ë°ì´í„°': item['DATA_VALUE']} for item in mid]\n",
        "    df = pd.DataFrame(data=extracted_data)\n",
        "    return df\n",
        "\n",
        "df_usd_krw = fetch_data('731Y001', 'D', '0000001', '','20040101')\n",
        "df_open = fetch_data('731Y003', 'D', '0000002','','20040101')\n",
        "df_low = fetch_data('731Y003', 'D', '0000004','','20040101')\n",
        "df_high = fetch_data('731Y003', 'D', '0000005','','20040101')\n",
        "df_close = fetch_data('731Y003', 'D', '0000003','','20040101')\n",
        "\n",
        "# ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ê³  ë°ì´í„°í”„ë ˆì„ì„ ë³‘í•©\n",
        "df_open.set_index('DATE', inplace=True)\n",
        "df_low.set_index('DATE', inplace=True)\n",
        "df_high.set_index('DATE', inplace=True)\n",
        "df_close.set_index('DATE', inplace=True)\n",
        "\n",
        "df_open = df_open.rename(columns={'ë°ì´í„°': 'Open'})\n",
        "df_low = df_low.rename(columns={'ë°ì´í„°': 'Low'})\n",
        "df_high = df_high.rename(columns={'ë°ì´í„°': 'High'})\n",
        "df_close = df_close.rename(columns={'ë°ì´í„°': 'Close'})\n",
        "\n",
        "df = df_open.join([df_low, df_high, df_close], how='inner')\n",
        "df.index = pd.to_datetime(df.index,format='%Y%m%d')\n",
        "\n",
        "# dashboard íƒ­\n",
        "if tabs =='Dashboard':\n",
        "    ## ì‹¤ì œí™˜ìœ¨ë§Œ ìˆëŠ” ê·¸ë˜í”„\n",
        "    # ì œëª©\n",
        "    st.title('ì›/ë‹¬ëŸ¬ í™˜ìœ¨')\n",
        "    # Fetch today's exchange rate\n",
        "    rate = pd.read_csv('ì§€ìˆ˜.csv')\n",
        "\n",
        "    rate['í™˜ìœ¨'] = pd.to_numeric(rate['í™˜ìœ¨'])\n",
        "\n",
        "    today_rate = rate['í™˜ìœ¨'].iloc[-1]\n",
        "\n",
        "    # Fetch yesterday's exchange rate\n",
        "    yesterday_rate = rate['í™˜ìœ¨'].iloc[-2]\n",
        "\n",
        "    # Calculate the change\n",
        "    change = today_rate - yesterday_rate\n",
        "    percentage_change = (change / yesterday_rate) * 100\n",
        "\n",
        "    st.metric(label=\"ë§¤ë§¤ê¸°ì¤€ìœ¨\", value=f\"{today_rate:.2f}\", delta=f\"{change:.2f} ({percentage_change:.2f}%)\",delta_color ='inverse')\n",
        "\n",
        "    tab1, tab2 = st.tabs(['ì¼ë°˜','ì°¨íŠ¸'])\n",
        "\n",
        "    with tab1:\n",
        "        ## ì˜ì—­ ê·¸ë˜í”„\n",
        "        # ì˜ì—­ ê·¸ë˜í”„ ìƒì„±\n",
        "        fig_area = px.area(df, x=df.index, y='Close')\n",
        "        fig_area.update_layout(xaxis_title='ë‚ ì§œ',yaxis_title='í™˜ìœ¨',yaxis=dict(range=[800, 1600]))\n",
        "\n",
        "        fig_area.update_traces(hovertemplate='<b>%{x|%Y-%m-%d}</b><br>' + 'ì‹œê°€: %{customdata[0]:.2f}<br>' + 'ê³ ê°€: %{customdata[1]:.2f}<br>'+'ì €ê°€: %{customdata[2]:.2f}<br>' +'ì¢…ê°€: %{y:.2f}<br>',customdata=df[['Open', 'High', 'Low']].values)\n",
        "\n",
        "        # hover ìŠ¤íƒ€ì¼ í¸ì§‘\n",
        "        fig_area.update_layout(hoverlabel_bgcolor=\"white\",hoverlabel_font_size=12,hoverlabel_font_family=\"Rockwell\")\n",
        "\n",
        "        # Streamlitì— ê·¸ë˜í”„ í‘œì‹œ\n",
        "        st.plotly_chart(fig_area, use_container_width=True)\n",
        "\n",
        "    with tab2:\n",
        "        # Define colors\n",
        "        COLOR_UP = 'rgba(255, 0, 0, 0.9)'   # Blue for bullish (rising) candles\n",
        "        COLOR_DOWN = 'rgba(0, 0, 255, 0.9)' # Red for bearish (falling) candles\n",
        "\n",
        "        # Fetch data function\n",
        "        def fetch_data(stat_code, cycle, item_code1, item_code2, start_date):\n",
        "            today_date = datetime.today().strftime('%Y%m%d')\n",
        "            url = f'http://ecos.bok.or.kr/api/StatisticSearch/P4JHAI59YVHQEHBFFOTX/json/kr/1/10000/{stat_code}/{cycle}/{start_date}/{today_date}/{item_code1}/{item_code2}/'\n",
        "            response = requests.get(url)\n",
        "            data = response.text\n",
        "            api_dict = json.loads(data)\n",
        "            mid = api_dict['StatisticSearch']['row']\n",
        "            extracted_data = [{'DATE': item['TIME'], 'ë°ì´í„°': item['DATA_VALUE']} for item in mid]\n",
        "            df = pd.DataFrame(data=extracted_data)\n",
        "            return df\n",
        "\n",
        "        # Fetching exchange rate data\n",
        "        df_usd_krw = fetch_data('731Y001', 'D', '0000001', '', '20040101')\n",
        "        df_open = fetch_data('731Y003', 'D', '0000002', '', '20040101')\n",
        "        df_low = fetch_data('731Y003', 'D', '0000004', '', '20040101')\n",
        "        df_high = fetch_data('731Y003', 'D', '0000005', '', '20040101')\n",
        "        df_close = fetch_data('731Y003', 'D', '0000003', '', '20040101')\n",
        "\n",
        "        # Setting DATE as index and merging dataframes\n",
        "        df_open.set_index('DATE', inplace=True)\n",
        "        df_low.set_index('DATE', inplace=True)\n",
        "        df_high.set_index('DATE', inplace=True)\n",
        "        df_close.set_index('DATE', inplace=True)\n",
        "\n",
        "        df_open = df_open.rename(columns={'ë°ì´í„°': 'open'})\n",
        "        df_low = df_low.rename(columns={'ë°ì´í„°': 'low'})\n",
        "        df_high = df_high.rename(columns={'ë°ì´í„°': 'high'})\n",
        "        df_close = df_close.rename(columns={'ë°ì´í„°': 'close'})\n",
        "\n",
        "        df = pd.concat([df_open, df_low, df_high, df_close], axis=1).reset_index()\n",
        "        df['datetime'] = pd.to_datetime(df['DATE'])\n",
        "        df['time'] = df['datetime'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "        # Export to JSON format\n",
        "        candles = json.loads(df.filter(['time', 'open', 'high', 'low', 'close'], axis=1).to_json(orient=\"records\"))\n",
        "\n",
        "        chartMultipaneOptions = [\n",
        "            {\n",
        "                \"layout\": {\n",
        "                    \"background\": {\n",
        "                        \"type\": \"solid\",\n",
        "                        \"color\": 'white'\n",
        "                    },\n",
        "                    \"textColor\": \"black\"\n",
        "                },\n",
        "                \"grid\": {\n",
        "                    \"vertLines\": {\n",
        "                        \"color\": \"rgba(197, 203, 206, 0.5)\"\n",
        "                    },\n",
        "                    \"horzLines\": {\n",
        "                        \"color\": \"rgba(197, 203, 206, 0.5)\"\n",
        "                    }\n",
        "                },\n",
        "                \"crosshair\": {\n",
        "                    \"mode\": 0\n",
        "                },\n",
        "                \"priceScale\": {\n",
        "                    \"borderColor\": \"rgba(197, 203, 206, 0.8)\",\n",
        "                    \"scaleMargins\": {\n",
        "                        \"top\": 0.1,\n",
        "                        \"bottom\": 0.1\n",
        "                    }\n",
        "                },\n",
        "                \"timeScale\": {\n",
        "                    \"borderColor\": \"rgba(197, 203, 206, 0.8)\",\n",
        "                    \"barSpacing\": 10,\n",
        "                    \"minBarSpacing\": 8,\n",
        "                    \"timeVisible\": False,\n",
        "                    \"secondsVisible\": False\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        seriesCandlestickChart = [\n",
        "            {\n",
        "                \"type\": 'Candlestick',\n",
        "                \"data\": candles,\n",
        "                \"options\": {\n",
        "                    \"upColor\": COLOR_UP,\n",
        "                    \"downColor\": COLOR_DOWN,\n",
        "                    \"borderVisible\": True,\n",
        "                    \"wickUpColor\": COLOR_UP,\n",
        "                    \"wickDownColor\": COLOR_DOWN,\n",
        "                    \"borderUpColor\": COLOR_UP,\n",
        "                    \"borderDownColor\": COLOR_DOWN\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        renderLightweightCharts([\n",
        "            {\n",
        "                \"chart\": chartMultipaneOptions[0],\n",
        "                \"series\": seriesCandlestickChart\n",
        "            }\n",
        "        ], 'multipane')\n",
        "\n",
        "\n",
        "\n",
        "    st.subheader(' ',divider='grey')\n",
        "\n",
        "    name, pop = st.columns([10,50])\n",
        "    name.title('í™˜ìœ¨ ì˜ˆì¸¡')\n",
        "\n",
        "    with pop:\n",
        "        popover = st.popover(\":grey_question:\")\n",
        "        multi = '''**ì¼ë³„**\n",
        "        ì¼ë³„ ì˜ˆì¸¡ í™˜ìœ¨ì€ ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.\n",
        "        ì²«ì§¸, 30ì¼ì¹˜ ì˜ˆì¸¡ê°’ì„ í•œëˆˆì— ë³¼ ìˆ˜ ìˆëŠ” ê·¸ë˜í”„ë¡œ ì œê³µí•˜ë©°, ì£¼ë§ì—ëŠ” ê¸ˆìš”ì¼ ì˜ˆì¸¡ê°’ì´ í‘œì‹œë©ë‹ˆë‹¤.\n",
        "        ë‘˜ì§¸, ì›í•˜ëŠ” ë¯¸ë˜ ë‚ ì§œë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ë‚ ì§œì˜ ì˜ˆì¸¡ê°’ì„ ì¦‰ì‹œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "        **ì›”ë³„**\n",
        "        ì´í›„ 3ê°œì›”ì˜ ì›”ë³„ í™˜ìœ¨ì„ ì˜ˆì¸¡í•œ ê²°ê³¼ê°’ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "        ê° ì›”ë³„ ì˜ˆì¸¡ í™˜ìœ¨ì€ í•´ë‹¹ ë‹¬ì˜ ë§ì¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "        **í™˜ìœ¨ê³„ì‚°ê¸°**\n",
        "        ì´ í™˜ìœ¨ ì˜ˆì¸¡ ê³„ì‚°ê¸°ëŠ” ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê¸ˆì•¡ì„ ì…ë ¥í•˜ë©´ ì˜ˆì¸¡ëœ í™˜ìœ¨ì„ ì‚¬ìš©í•˜ì—¬ ë³€í™˜ëœ ê¸ˆì•¡ì„ ê³„ì‚°í•´ì¤ë‹ˆë‹¤.\n",
        "        ë³€í™˜ëœ ì›í™” ê¸ˆì•¡ì€ ì†Œìˆ˜ì  ë‘ ë²ˆì§¸ ìë¦¬ê¹Œì§€ í‘œì‹œë©ë‹ˆë‹¤.\n",
        "        '''\n",
        "        popover.markdown(multi)\n",
        "\n",
        "    left, right = st.columns([10,5])\n",
        "\n",
        "    with left:\n",
        "        left.markdown(\"<h3 style='font-size: medium;'>ì¼ë³„</h3>\", unsafe_allow_html=True)\n",
        "        # CSV íŒŒì¼ ì½ê¸°\n",
        "        pred_dates_df1 = pd.read_csv('pred.csv')\n",
        "\n",
        "        # ë°ì´í„° í”„ë ˆì„ ì„¤ì •\n",
        "        pred_dates_df1['ë‚ ì§œ'] = pd.to_datetime(pred_dates_df1['ë‚ ì§œ'])\n",
        "\n",
        "        # 30ì¼ì¼ ë°ì´í„°ë§Œ ì„ íƒ\n",
        "        pred_dates_df1 = pred_dates_df1.head(30)\n",
        "\n",
        "        # í¼ì„¼íŠ¸ ë³€í™” ê³„ì‚°\n",
        "        pred_dates_df1['ë³€í™”ìœ¨'] = pred_dates_df1['ì˜ˆì¸¡í™˜ìœ¨'].pct_change() * 100\n",
        "\n",
        "        # ì²« ë²ˆì§¸ ë‚  ë° NaN ê°’ ì²˜ë¦¬\n",
        "        pred_dates_df1['ë³€í™”ìœ¨'].iloc[0] = 0\n",
        "\n",
        "        # í™”ì‚´í‘œì™€ í¼ì„¼íŠ¸ ë³€í™” ì¶”ê°€\n",
        "        def format_change_text(row):\n",
        "            if row['ë³€í™”ìœ¨'] == 0 or np.isnan(row['ë³€í™”ìœ¨']):\n",
        "                return \"<span style='color: grey;'>&nbsp;-</span>\"\n",
        "            elif row['ë³€í™”ìœ¨'] > 0:\n",
        "                return f\"<span style='color: red;'>â–² {row['ë³€í™”ìœ¨']:.2f}%</span>\"\n",
        "            else:\n",
        "                return f\"<span style='color: blue;'>â–¼ {row['ë³€í™”ìœ¨']:.2f}%</span>\"\n",
        "\n",
        "        pred_dates_df1['ë³€í™”_í…ìŠ¤íŠ¸'] = pred_dates_df1.apply(format_change_text, axis=1)\n",
        "\n",
        "        # ê·¸ë˜í”„ ìƒì„±\n",
        "        fig = go.Figure()\n",
        "\n",
        "        # ì˜ˆì¸¡ í™˜ìœ¨ ë°ì´í„° ì¶”ê°€\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=pred_dates_df1['ë‚ ì§œ'],\n",
        "            y=pred_dates_df1['ì˜ˆì¸¡í™˜ìœ¨'],\n",
        "            mode='lines+markers',\n",
        "            marker=dict(color='green', size=6),\n",
        "            name='ì˜ˆì¸¡í™˜ìœ¨',\n",
        "            line=dict(color='green'),\n",
        "            hovertemplate='<b>%{x|%Y-%m-%d}</b><br>ì˜ˆì¸¡í™˜ìœ¨: %{y}<br><span style=\"text-align: center; display: block;\">ë³€í™”ìœ¨: %{customdata}</span><extra></extra>',\n",
        "            customdata=pred_dates_df1['ë³€í™”_í…ìŠ¤íŠ¸'],\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "        # ì˜¤ì°¨ë²”ìœ„ ì¶”ê°€\n",
        "        fig.add_trace(go.Scatter(x=pred_dates_df1['ë‚ ì§œ'].tolist() + pred_dates_df1['ë‚ ì§œ'][::-1].tolist(),y=pred_dates_df1['ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœëŒ€'].tolist() + pred_dates_df1['ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœì†Œ'][::-1].tolist(),fill='toself',fillcolor='rgba(0,100,80,0.2)',line_color='rgba(255,255,255,0)',hoverinfo=\"skip\",showlegend=False))\n",
        "\n",
        "\n",
        "        # ê·¸ë˜í”„ ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
        "        fig.update_layout(xaxis_title='ë‚ ì§œ', yaxis_title='í™˜ìœ¨', xaxis=dict(tickformat='%Y-%m-%d'))\n",
        "\n",
        "        # hover ìŠ¤íƒ€ì¼ í¸ì§‘\n",
        "        fig.update_layout(hoverlabel_bgcolor=\"white\", hoverlabel_font_size=12, hoverlabel_font_family=\"Rockwell\")\n",
        "\n",
        "        # ê·¸ë˜í”„ í‘œì‹œ\n",
        "        left.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    with right:\n",
        "        ## ì˜ˆì¸¡ ê°’ í‘œì‹œ\n",
        "        # CSV íŒŒì¼ ì½ê¸°\n",
        "        pred_dates_df1 = pd.read_csv('pred.csv')\n",
        "\n",
        "        # ë°ì´í„° í”„ë ˆì„ ì„¤ì •\n",
        "        pred_dates_df1['ë‚ ì§œ'] = pd.to_datetime(pred_dates_df1['ë‚ ì§œ'])\n",
        "\n",
        "        # 30ì¼ ë°ì´í„°ë§Œ ì„ íƒ\n",
        "        pred_dates_df1 = pred_dates_df1.head(30)\n",
        "\n",
        "        # ë‚ ì§œ ì„ íƒ\n",
        "        date_input = st.date_input(':date:', value=pred_dates_df1['ë‚ ì§œ'].min(), min_value = pred_dates_df1['ë‚ ì§œ'].min(), max_value = pred_dates_df1['ë‚ ì§œ'].max())\n",
        "\n",
        "        # ë‚ ì§œ ì…ë ¥ ë° ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n",
        "        if date_input:\n",
        "            try:\n",
        "                date = pd.to_datetime(date_input)\n",
        "                if date in pred_dates_df1['ë‚ ì§œ'].values:\n",
        "                    row = pred_dates_df1[pred_dates_df1['ë‚ ì§œ'] == date]\n",
        "                    pred_value = row['ì˜ˆì¸¡í™˜ìœ¨'].values[0]\n",
        "                    if date.weekday() == 5 or date.weekday() == 6:\n",
        "                        st.write(':red[ì£¼ë§ì—ëŠ” í™˜ìœ¨ì´ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.]')\n",
        "                    else:\n",
        "                        st.write(f\"{date_input.strftime('%Y-%m-%d')}ì˜ ì˜ˆì¸¡í™˜ìœ¨: {row['ì˜ˆì¸¡í™˜ìœ¨'].values[0]}\")\n",
        "                        st.write(f\"{date_input.strftime('%Y-%m-%d')}ì˜ ì˜ˆì¸¡í™˜ìœ¨ ë²”ìœ„: {row['ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœì†Œ'].values[0]} ~ {row['ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœëŒ€'].values[0]}\")\n",
        "                else:\n",
        "                    st.write(\"í•´ë‹¹ ë‚ ì§œê°€ ì˜ˆì¸¡ë²”ìœ„ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            except Exception as e:\n",
        "                st.write(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "\n",
        "        st.subheader(' ')\n",
        "\n",
        "        ## í™˜ìœ¨ ê³„ì‚°ê¸°\n",
        "        # í™˜ìœ¨ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "        df1 = pd.read_csv('pred.csv')\n",
        "\n",
        "        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”\n",
        "        if 'calculate_usd' not in st.session_state:\n",
        "            st.session_state.calculate_usd = False\n",
        "        if 'calculate_krw' not in st.session_state:\n",
        "            st.session_state.calculate_krw = False\n",
        "\n",
        "        # íŒì—…í‘œì‹œ\n",
        "        with st.expander('í™˜ìœ¨ ê³„ì‚°ê¸°'):\n",
        "            # ë‚ ì§œ ì…ë ¥ ìœ„ì ¯ (ë°ì´í„°ì…‹ ë‚´ì˜ ë¯¸ë˜ ë‚ ì§œ í—ˆìš©)\n",
        "            d_today = datetime.today().date()\n",
        "            d_tomorrow = d_today + timedelta(days=1)\n",
        "            d_max = pd.to_datetime(df1['ë‚ ì§œ'].head(30)).max().date()\n",
        "            selected_date = st.date_input('ë‚ ì§œ ì„ íƒ', value=d_tomorrow, min_value=d_tomorrow, max_value=d_max)\n",
        "            formatted_date = selected_date.strftime('%Y-%m-%d')\n",
        "\n",
        "            # ì„ íƒëœ ë‚ ì§œê°€ ì£¼ë§ì¸ì§€ í™•ì¸\n",
        "            is_weekend = selected_date.weekday() >= 5\n",
        "\n",
        "            # í™˜ìœ¨ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
        "            def get_exchange_rate(date):\n",
        "                data = df1[df1['ë‚ ì§œ'] == date]\n",
        "                if not data.empty:\n",
        "                    return data['ì˜ˆì¸¡í™˜ìœ¨'].values[0]\n",
        "                else:\n",
        "                    return None\n",
        "\n",
        "            if is_weekend:\n",
        "                st.warning(\"ì£¼ë§ì—ëŠ” í™˜ìœ¨ì´ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
        "            else:\n",
        "                exchange_rate = get_exchange_rate(formatted_date)\n",
        "\n",
        "                if exchange_rate:\n",
        "                    # ì…ë ¥ ì¹¸ ë‘ ê°œ (ì›í™”/ì™¸í™”)\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "\n",
        "                    # ì›í™” ì…ë ¥\n",
        "                    with col1:\n",
        "                        krw_amount1 = st.number_input('ë³€í™˜í•  ì›í™”(KRW) ê¸ˆì•¡ ì…ë ¥', min_value=0, key='krw_amount')\n",
        "                        if krw_amount1 > 0:\n",
        "                            st.session_state.calculate_usd = True\n",
        "                            st.session_state.calculate_krw = False\n",
        "                        else:\n",
        "                            st.session_state.calculate_usd = False\n",
        "\n",
        "                    # ì™¸í™” ì…ë ¥\n",
        "                    with col2:\n",
        "                        usd_amount2 = st.number_input('ë³€í™˜í•  ì™¸í™”(USD) ê¸ˆì•¡ ì…ë ¥', min_value=0.0, key='usd_amount')\n",
        "                        if usd_amount2 > 0:\n",
        "                            st.session_state.calculate_usd = False\n",
        "                            st.session_state.calculate_krw = True\n",
        "                        else:\n",
        "                            st.session_state.calculate_krw = False\n",
        "\n",
        "                    # ê³„ì‚° ìˆ˜í–‰\n",
        "                    if st.session_state.calculate_usd and krw_amount1 > 0:\n",
        "                        # ì›í™”ë¥¼ ë‹¬ëŸ¬ë¡œ ë³€í™˜\n",
        "                        usd_amount_converted = krw_amount1 / exchange_rate\n",
        "                        col1, col2, col3 = st.columns([4, 2, 4])\n",
        "                        with col1:\n",
        "                            st.header(\"ë¯¸êµ­(USD)\")\n",
        "                            st.subheader(f'{usd_amount_converted:.2f} USD')\n",
        "                        with col2:\n",
        "                            st.image('arrow-left-right.svg', width=50)\n",
        "                        with col3:\n",
        "                            st.header(\"í•œêµ­(KRW)\")\n",
        "                            st.subheader(f'{krw_amount1:,} ì›')\n",
        "                    elif st.session_state.calculate_krw and usd_amount2 > 0:\n",
        "                        # ë‹¬ëŸ¬ë¥¼ ì›í™”ë¡œ ë³€í™˜\n",
        "                        krw_amount_converted = round(usd_amount2 * exchange_rate)\n",
        "                        col1, col2, col3 = st.columns([4, 2, 4])\n",
        "                        with col1:\n",
        "                            st.header(\"ë¯¸êµ­(USD)\")\n",
        "                            st.subheader(f'{usd_amount2:.2f} USD')\n",
        "                        with col2:\n",
        "                            st.image('arrow-left-right.svg', width=50)\n",
        "                        with col3:\n",
        "                            st.header(\"í•œêµ­(KRW)\")\n",
        "                            st.subheader(f'{krw_amount_converted:,} ì›')\n",
        "                    else:\n",
        "                        st.warning(\"ì›í™” ë˜ëŠ” ì™¸í™” ê¸ˆì•¡ì„ ì…ë ¥í•˜ì„¸ìš”.\")\n",
        "                else:\n",
        "                    st.error(\"ì„ íƒí•œ ë‚ ì§œì— ëŒ€í•œ í™˜ìœ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    st.markdown('---')\n",
        "\n",
        "    left_, right_ = st.columns([10,5])\n",
        "    with left_:\n",
        "        left_.markdown(\"<h4 style='font-size: medium;'>ì›”ë³„</h4>\", unsafe_allow_html=True)\n",
        "        ## ì˜ˆì¸¡í™˜ìœ¨ - ì›”ë³„\n",
        "        # CSV íŒŒì¼ ì½ê¸°\n",
        "        pred_dates_month = pd.read_csv('í™˜ìœ¨ì˜ˆì¸¡_ì›”ë³„.csv')\n",
        "        pred_dates_month = pred_dates_month.iloc[:3,:]\n",
        "\n",
        "       # HTML í…Œì´ë¸” ìƒì„±\n",
        "        html_table_month = pred_dates_month.to_html(index=False, justify='center')\n",
        "\n",
        "        # CSSë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ìš´ë° ì •ë ¬ ë° ë„ˆë¹„ ì¡°ì •\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            <style>\n",
        "            .month-table {\n",
        "                width: 100%;\n",
        "                margin: 0 auto;\n",
        "            }\n",
        "            .month-table table {\n",
        "                width: 100%;\n",
        "                table-layout: fixed;\n",
        "            }\n",
        "            .month-table th, .month-table td {\n",
        "                text-align: center !important;\n",
        "            }\n",
        "            </style>\n",
        "            \"\"\",\n",
        "            unsafe_allow_html=True\n",
        "        )\n",
        "\n",
        "        # HTML í…Œì´ë¸” ì¶œë ¥\n",
        "        st.markdown(f'<div class=\"month-table\">{html_table_month}</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with right_:\n",
        "        col1_, col2_ = right_.columns([10,1])\n",
        "\n",
        "\n",
        "        # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ê´€ë ¨ ì½”ë“œ\n",
        "        col1_.subheader('í…”ë ˆê·¸ë¨ ì•Œë¦¼')\n",
        "\n",
        "        with col2_:\n",
        "            popover = st.popover(\":grey_question:\")\n",
        "            multi = ''' **QR ì½”ë“œ ìŠ¤ìº”**\n",
        "            - ì•„ë˜ QR ì½”ë“œë¥¼ ìŠ¤ìº”í•˜ì—¬ í…”ë ˆê·¸ë¨ ëŒ€í™”ë°©ì— ì…ì¥í•˜ì„¸ìš”.\n",
        "            - í…”ë ˆê·¸ë¨ ì•±ì´ ì—†ëŠ” ê²½ìš°, ë¨¼ì € ì•±ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  íšŒì›ê°€ì…ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.\n",
        "            **í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì„¤ì •**\n",
        "            - \"í…”ë ˆê·¸ë¨ ì•Œë¦¼ ë°›ê¸°\"ë¥¼ ëˆŒëŸ¬ ì˜ˆì¸¡ í™˜ìœ¨ ì •ë³´ë¥¼ í¸ë¦¬í•˜ê²Œ íœ´ëŒ€í°ìœ¼ë¡œ ë°›ì•„ë³´ì„¸ìš”. ì´ ê¸°ëŠ¥ì„ í†µí•´ ë‹¤ìŒ ë‚ ì˜ í™˜ìœ¨ ì˜ˆì¸¡ê°’ì„ ì•Œë¦¼ìœ¼ë¡œ ë°›ê³ , íœ´ëŒ€í°ì—ì„œë„ ì†ì‰½ê²Œ í™˜ìœ¨ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "            '''\n",
        "            popover.markdown(multi)\n",
        "\n",
        "        qr, button = right_.columns(2)\n",
        "        qr.image('í…”ë ˆê·¸ë¨_qrì½”ë“œ.png',caption = 'í…”ë ˆê·¸ë¨ ì ‘ì† QR')\n",
        "\n",
        "        # í…”ë ˆê·¸ë¨ ë´‡ í† í°ê³¼ ì±„ë„ ID ì„¤ì •\n",
        "        TELEGRAM_BOT_TOKEN = \"7445529925:AAGDMvyDYyc3FNQgKa0FBrOqWBHp9DbbdBw\"\n",
        "        bot = Bot(token = TELEGRAM_BOT_TOKEN)\n",
        "        chat_id = -1002180124685\n",
        "        alarm_started = False\n",
        "        scheduler_thread = None\n",
        "\n",
        "        def send_telegram_message(chat_id, message):\n",
        "            try:\n",
        "                url = f'https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage'\n",
        "                payload = {\n",
        "                    'chat_id': chat_id,\n",
        "                    'text': message\n",
        "                }\n",
        "                response = requests.post(url, json=payload)\n",
        "                if response.status_code != 200:\n",
        "                    st.write(f\"Failed to send message: {response.status_code} - {response.text}\")\n",
        "            except Exception as e:\n",
        "                st.write(f\"Error sending message: {e}\")\n",
        "\n",
        "        def daily_alarm():\n",
        "            try:\n",
        "                today = datetime.now()\n",
        "                today_str = today.strftime('%Y-%m-%d')\n",
        "                next_day = datetime.now() + timedelta(days=1)\n",
        "                next_day_str = next_day.strftime('%Y-%m-%d')\n",
        "                button.write(f\"Preparing message for {next_day_str}\")\n",
        "                # ì˜ˆì¸¡ë‚ ì§œ_ì¼ë³„ ì—´ì˜ ë‚ ì§œ í˜•ì‹ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ\n",
        "                pred_dates_df1['ë‚ ì§œ'] = pd.to_datetime(pred_dates_df1['ë‚ ì§œ']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "                if next_day_str in pred_dates_df1['ë‚ ì§œ'].values:\n",
        "                    row = pred_dates_df1[pred_dates_df1['ë‚ ì§œ'] == next_day_str]\n",
        "                    pred_value = row['ì˜ˆì¸¡í™˜ìœ¨'].values[0]\n",
        "                    today_value = df_usd_krw.iloc[-1].values[1]\n",
        "\n",
        "                    if date.weekday() == 5 or date.weekday() == 6:\n",
        "                        send_telegram_message(chat_id, f\"ë‚´ì¼({next_day_str})ì€ ì£¼ë§ì´ë¯€ë¡œ í™˜ìœ¨ ë°ì´í„°ê°€ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
        "                    else:\n",
        "                        message = f\"ì˜¤ëŠ˜({today_str})ì˜ í™˜ìœ¨ : {today_value}ì›\\n\"\\\n",
        "                                    f\"ë‚´ì¼({next_day_str})ì˜ ì˜ˆì¸¡í™˜ìœ¨ : {pred_value}\\n\"\\\n",
        "                                    f\"ì˜ˆì¸¡í™˜ìœ¨ ë²”ìœ„ : {row['ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœì†Œ'].values[0]} ~ {row['ì˜ˆì¸¡í™˜ìœ¨_ì¼ë³„_ìµœëŒ€'].values[0]}\"\n",
        "                        send_telegram_message(chat_id, message)\n",
        "                else:\n",
        "                    send_telegram_message(chat_id, f\"ë‚´ì¼({next_day_str})ì˜ ì˜ˆì¸¡í™˜ìœ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            except Exception as e:\n",
        "                button.write(f\"Error in daily_alarm: {e}\")\n",
        "\n",
        "\n",
        "        def start_alarm():\n",
        "            global alarm_started, scheduler_thread\n",
        "            if not alarm_started:\n",
        "                send_telegram_message(chat_id, \"ì•Œë¦¼ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤\")\n",
        "                button.write(\"ì•Œë¦¼ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤\")\n",
        "                schedule.every().day.at(\"09:40\").do(daily_alarm)\n",
        "                alarm_started = True\n",
        "                scheduler_thread = threading.Thread(target=run_scheduler)\n",
        "                scheduler_thread.start()\n",
        "                daily_alarm()  # Start immediately for testing\n",
        "\n",
        "        def stop_alarm():\n",
        "            global alarm_started\n",
        "            send_telegram_message(chat_id, \"ì•Œë¦¼ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤\")\n",
        "            button.write(\"ì•Œë¦¼ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤\")\n",
        "            if alarm_started:\n",
        "                schedule.clear()\n",
        "                alarm_started = False\n",
        "\n",
        "        def run_scheduler():\n",
        "            while alarm_started:\n",
        "                schedule.run_pending()\n",
        "                time.sleep(1)\n",
        "\n",
        "        if button.button('í…”ë ˆê·¸ë¨ ì•Œë¦¼ ë°›ê¸°'):\n",
        "            if not alarm_started:\n",
        "                start_alarm()\n",
        "            else:\n",
        "                button.write(\"ì´ë¯¸ ì•Œë¦¼ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "elif tabs == 'Keyword':\n",
        "    ## í‚¤ì›Œë“œ - ë³€ê³¡ì \n",
        "    # ì œëª©\n",
        "    st.title('í‚¤ì›Œë“œ ë¶„ì„')\n",
        "\n",
        "    col1, col2 = st.columns([10, 0.5])\n",
        "\n",
        "    # CSV íŒŒì¼ ì½ê¸°\n",
        "    df = pd.read_csv('ìµœì¢….csv')\n",
        "    keyword_df = pd.read_csv('í™˜ìœ¨(ê²½ì œ)_ìˆ˜ì •.csv')\n",
        "\n",
        "    # ë°ì´í„° í”„ë ˆì„ ì„¤ì •\n",
        "    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])\n",
        "    df.set_index('ë‚ ì§œ', inplace=True)\n",
        "\n",
        "    # í‚¤ì›Œë“œ ë°ì´í„° í”„ë ˆì„ ì„¤ì •\n",
        "    keyword_df['ì¼ì'] = pd.to_datetime(keyword_df['ì¼ì'])\n",
        "    keyword_df.set_index('ì¼ì', inplace=True)\n",
        "\n",
        "    # ì´ë™ í‰ê·  ê³„ì‚°\n",
        "    df['100ì¼ ì´ë™ í‰ê· '] = df['í™˜ìœ¨'].rolling(window=100, min_periods=1).mean()\n",
        "\n",
        "    # ë³€ê³¡ì  íƒì§€\n",
        "    df['Signal'] = 0.0\n",
        "    df.iloc[100:, df.columns.get_loc('Signal')] = np.where(df['í™˜ìœ¨'][100:] > df['100ì¼ ì´ë™ í‰ê· '][100:], 1.0, 0.0)\n",
        "    df['Position'] = df['Signal'].diff()\n",
        "\n",
        "    # ë³€ê³¡ì  í•„í„°ë§ (30ì¼ ì´ìƒì˜ ê°„ê²©)\n",
        "    filtered_positions = []\n",
        "    last_date = df.index[0]\n",
        "    for date, pos in df['Position'][df['Position'] != 0].items():\n",
        "        if (date - last_date).days >= 30:\n",
        "            filtered_positions.append((date, pos))\n",
        "            last_date = date\n",
        "\n",
        "    # í‚¤ì›Œë“œ ì§‘ê³„ í•¨ìˆ˜\n",
        "    def get_top_keywords(date, keyword_df, days=30, top_n=10):\n",
        "        start_date = date - pd.Timedelta(days=days)\n",
        "        relevant_keywords = keyword_df.loc[start_date:date]\n",
        "        all_text = ' '.join(relevant_keywords['íŠ¹ì„±ì¶”ì¶œ(ê°€ì¤‘ì¹˜ìˆœ ìƒìœ„ 50ê°œ)'].tolist())\n",
        "        tokens = all_text.split(',')\n",
        "        word_counts = Counter(tokens)\n",
        "        top_keywords_tuples = collections.Counter(word_counts).most_common(top_n)\n",
        "        top_keywords = [keyword for keyword, count in top_keywords_tuples]\n",
        "        return top_keywords\n",
        "\n",
        "    # í”Œë¡œí‹€ë¦¬ ê·¸ë˜í”„ ìƒì„±\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=df.index, y=df['í™˜ìœ¨'], mode='lines', name='í™˜ìœ¨', line=dict(color='gray')))\n",
        "\n",
        "    # ë³€ê³¡ì  ì¶”ê°€\n",
        "    added_legends = {\"ìƒìŠ¹\": False, \"í•˜ë½\": False}  # ë²”ë¡€ í‘œì‹œë¥¼ ìœ„í•œ í”Œë˜ê·¸\n",
        "\n",
        "    for date, pos in filtered_positions:\n",
        "        top_keywords = get_top_keywords(date, keyword_df)\n",
        "        hover_text = f\"<br>ìƒìœ„ í‚¤ì›Œë“œ:<br>\" + \"<br>\".join(top_keywords)\n",
        "        showlegend = False\n",
        "        if pos == 1 and not added_legends[\"ìƒìŠ¹\"]:\n",
        "            showlegend = True\n",
        "            added_legends[\"ìƒìŠ¹\"] = True\n",
        "        elif pos == -1 and not added_legends[\"í•˜ë½\"]:\n",
        "            showlegend = True\n",
        "            added_legends[\"í•˜ë½\"] = True\n",
        "\n",
        "        marker_symbol = 'triangle-up' if pos == 1 else 'triangle-down'\n",
        "        marker_color = 'red' if pos == 1 else 'blue'\n",
        "        marker_name = 'ë³€ê³¡ì  (ìƒìŠ¹)' if pos == 1 else 'ë³€ê³¡ì  (í•˜ë½)'\n",
        "\n",
        "        fig.add_trace(go.Scatter( x=[date], y=[df['í™˜ìœ¨'].loc[date]], mode='markers', marker=dict(symbol=marker_symbol, color=marker_color, size=10),name=marker_name,hovertemplate=hover_text + '<extra></extra>' , showlegend=showlegend))\n",
        "\n",
        "    # ì„œë¸Œí”„ë¼ì„ ëª¨ê¸°ì§€ ì‚¬íƒœ\n",
        "    annotation_date = df[df.index == '2007-07-02']\n",
        "\n",
        "    fig.add_annotation(\n",
        "        x=annotation_date.index[0],  # ì£¼ì„ì„ ì¶”ê°€í•  ë‚ ì§œ\n",
        "        y=df.loc[annotation_date.index[0], 'í™˜ìœ¨'],  # ì£¼ì„ì„ ì¶”ê°€í•  y ê°’ (í™˜ìœ¨)\n",
        "        text=\"ì„œë¸Œí”„ë¼ì„ ëª¨ê¸°ì§€ ì‚¬íƒœ\",\n",
        "        font_color = 'black',\n",
        "        showarrow=True,\n",
        "        arrowhead=1\n",
        "    )\n",
        "\n",
        "    # ê¸€ë¡œë²Œ ê¸ˆìœµìœ„ê¸°\n",
        "    annotation_date = df[df.index == '2008-09-01']\n",
        "\n",
        "    fig.add_annotation(\n",
        "        x=annotation_date.index[0],  # ì£¼ì„ì„ ì¶”ê°€í•  ë‚ ì§œ\n",
        "        y=df.loc[annotation_date.index[0], 'í™˜ìœ¨'],  # ì£¼ì„ì„ ì¶”ê°€í•  y ê°’ (í™˜ìœ¨)\n",
        "        text=\"ê¸€ë¡œë²Œ ê¸ˆìœµìœ„ê¸°\",\n",
        "        font_color = 'black',\n",
        "        showarrow=True,\n",
        "        arrowhead=1\n",
        "    )\n",
        "\n",
        "    # covid-19\n",
        "    annotation_date = df[df.index == '2020-01-02']\n",
        "\n",
        "    fig.add_annotation(\n",
        "        x=annotation_date.index[0],  # ì£¼ì„ì„ ì¶”ê°€í•  ë‚ ì§œ\n",
        "        y=df.loc[annotation_date.index[0], 'í™˜ìœ¨'],  # ì£¼ì„ì„ ì¶”ê°€í•  y ê°’ (í™˜ìœ¨)\n",
        "        text=\"COVID-19\",\n",
        "        font_color = 'black',\n",
        "        showarrow=True,\n",
        "        arrowhead=1\n",
        "    )\n",
        "\n",
        "    # ëŸ¬ì‹œì•„-ìš°í¬ë¼ì´ë‚˜ ì „ìŸ\n",
        "    annotation_date = df[df.index == '2022-02-24']\n",
        "\n",
        "    fig.add_annotation(\n",
        "        x=annotation_date.index[0],  # ì£¼ì„ì„ ì¶”ê°€í•  ë‚ ì§œ\n",
        "        y=df.loc[annotation_date.index[0], 'í™˜ìœ¨'],  # ì£¼ì„ì„ ì¶”ê°€í•  y ê°’ (í™˜ìœ¨)\n",
        "        text=\"ëŸ¬ì‹œì•„-ìš°í¬ë¼ì´ë‚˜ ì „ìŸ \",\n",
        "        font_color = 'black',\n",
        "        showarrow=True,\n",
        "        arrowhead=1\n",
        "    )\n",
        "\n",
        "    # ë§ˆìš°ìŠ¤ ì˜¤ë²„ ì‹œ ë‚ ì§œì™€ í™˜ìœ¨ í‘œì‹œ\n",
        "    fig.update_layout(hovermode='x unified',xaxis_title='ë‚ ì§œ',yaxis_title='í™˜ìœ¨',legend=dict(x=0, y=1.0, bgcolor='rgba(255, 255, 255, 0)', bordercolor='rgba(255, 255, 255, 0)'))\n",
        "\n",
        "    # ê·¸ë˜í”„ ì¶œë ¥\n",
        "    col1.plotly_chart(fig)\n",
        "\n",
        "\n",
        "    with col2:\n",
        "        popover = st.popover(\":grey_question:\")\n",
        "        multi = '''ì´ ê·¸ë˜í”„ëŠ” 100ì¼ ì´ë™í‰ê· ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ í™˜ìœ¨ ë³€ê³¡ì  ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "        ë³€ê³¡ì  ìœ„ì— ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë¦¬ë©´ í•´ë‹¹ ë‚ ì§œì™€ í™˜ìœ¨ë¿ë§Œ ì•„ë‹ˆë¼, 100ì¼ê°„ì˜ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ì¶œí•œ ìƒìœ„ 10ê°œì˜ í‚¤ì›Œë“œë„ í•¨ê»˜ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "        - ìƒìŠ¹ ë³€ê³¡ì  : í™˜ìœ¨ì´ 100ì¼ ì´ë™í‰ê· ì„ ìƒíšŒí•˜ì—¬ ìƒìŠ¹í•˜ëŠ” ì‹œì  (ë¹¨ê°„ ì‚¼ê°í˜•)\n",
        "        - í•˜ë½ ë³€ê³¡ì  : í™˜ìœ¨ì´ 100ì¼ ì´ë™í‰ê· ì„ í•˜íšŒí•˜ì—¬ í•˜ë½í•˜ëŠ” ì‹œì  (íŒŒë€ ì‚¼ê°í˜•)\n",
        "        '''\n",
        "        popover.markdown(multi)\n",
        "\n",
        "    ## ë‚ ì§œ ì§€ì • í‚¤ì›Œë“œ\n",
        "    # CSV íŒŒì¼ ì½ê¸°\n",
        "    df = pd.read_csv('ìµœì¢….csv')\n",
        "    keyword_df = pd.read_csv('í™˜ìœ¨(ê²½ì œ)_ìˆ˜ì •.csv')\n",
        "\n",
        "    # ë‚ ì§œ í˜•ì‹ì„ datetimeìœ¼ë¡œ ë³€í™˜\n",
        "    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])\n",
        "    keyword_df['ì¼ì'] = pd.to_datetime(keyword_df['ì¼ì'])\n",
        "\n",
        "    # ìµœì†Œ ë° ìµœëŒ€ ë‚ ì§œ\n",
        "    min_date = keyword_df['ì¼ì'].min()\n",
        "    max_date = keyword_df['ì¼ì'].max()\n",
        "\n",
        "    col1, col2, col3 = st.columns([10,10,0.5])\n",
        "\n",
        "    with col1:\n",
        "        user_input_date_start = st.date_input(\"ì‹œì‘ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”\", value=min_date, min_value=min_date, max_value=max_date)\n",
        "\n",
        "    with col2:\n",
        "        user_input_date_end = st.date_input(\"ì¢…ë£Œ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”\", value=min_date, min_value=min_date, max_value=max_date)\n",
        "\n",
        "    with col3:\n",
        "        popover = st.popover(\":grey_question:\")\n",
        "        multi = '''ì‚¬ìš©ìê°€ ì§ì ‘ ì„¤ì •í•œ ê¸°ê°„ì— ë‚˜íƒ€ë‚˜ëŠ” ìƒìœ„ í‚¤ì›Œë“œ 20ê°œë¥¼ ë¹ˆë„ìˆ˜ì— ë”°ë¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "        ì´ ê¸°ëŠ¥ì€ ì‚¬ìš©ìê°€ íŠ¹ì • ê¸°ê°„ ë™ì•ˆ í™˜ìœ¨ ë³€ë™ ì´ìœ ë‚˜ ë‹¹ì‹œ ì´ìŠˆë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ë•ê¸° ìœ„í•´ ë§ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "        '''\n",
        "        popover.markdown(multi)\n",
        "\n",
        "    # ì‚¬ìš©ì ì…ë ¥ ë‚ ì§œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜\n",
        "    user_input_date_start = pd.to_datetime(user_input_date_start)\n",
        "    user_input_date_end = pd.to_datetime(user_input_date_end)\n",
        "\n",
        "    # ë‚ ì§œ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° ì„ íƒ\n",
        "    df_select = keyword_df.loc[(keyword_df['ì¼ì'] >= user_input_date_start) & (keyword_df['ì¼ì'] <= user_input_date_end)]\n",
        "\n",
        "    # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©\n",
        "    all_text = ' '.join(df_select['íŠ¹ì„±ì¶”ì¶œ(ê°€ì¤‘ì¹˜ìˆœ ìƒìœ„ 50ê°œ)'].tolist())\n",
        "\n",
        "    # ì‰¼í‘œ(,)ë¥¼ ë‹¨ìœ„ë¡œ í† í°í™”\n",
        "    tokens = all_text.split(',')\n",
        "\n",
        "    # ë‹¨ì–´ ë¹ˆë„ìˆ˜ ê³„ì‚°\n",
        "    word_counts = Counter(tokens)\n",
        "\n",
        "    # ë‹¨ì–´ ë¹ˆë„ìˆ˜ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
        "    word_freq_df = pd.DataFrame(word_counts.items(), columns=['ë‹¨ì–´', 'ë¹ˆë„ìˆ˜'])\n",
        "\n",
        "    # ë¹ˆë„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "    word_freq_df = word_freq_df.sort_values(by='ë¹ˆë„ìˆ˜', ascending=False)\n",
        "\n",
        "    # ìƒìœ„ 20ê°œ ë‹¨ì–´ ì¶”ì¶œ ë° ì¸ë±ìŠ¤ 1ë¶€í„° 20ìœ¼ë¡œ ì„¤ì •\n",
        "    top_20_words = word_freq_df.head(20).reset_index(drop=True)\n",
        "    top_20_words.index += 1\n",
        "\n",
        "    # HTML í…Œì´ë¸” ìƒì„±\n",
        "    html_table_keywords = top_20_words.to_html(index=False, justify='center')\n",
        "\n",
        "    # CSSë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ìš´ë° ì •ë ¬ ë° ë„ˆë¹„ ì¡°ì •\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        <style>\n",
        "        .keyword-table {\n",
        "            width: 100%;\n",
        "            margin: 0 auto;\n",
        "        }\n",
        "        .keyword-table table {\n",
        "            width: 100%;\n",
        "            table-layout: fixed;\n",
        "        }\n",
        "        .keyword-table th, .keyword-table td {\n",
        "            text-align: center !important;\n",
        "            width: 50%;\n",
        "        }\n",
        "        .keyword-table td {\n",
        "            color: black;\n",
        "        }\n",
        "        .keyword-table td:contains('red') {\n",
        "            color: red;\n",
        "        }\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "    # HTML í…Œì´ë¸” ì¶œë ¥\n",
        "    st.markdown(f'<div class=\"keyword-table\">{html_table_keywords}</div>', unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# information íƒ­\n",
        "elif tabs == 'Information':\n",
        "    # st.subheader(':blue[ëª¨ë¸ì˜ ì •í™•ë„]')\n",
        "    # CSV íŒŒì¼ ì½ê¸°\n",
        "    df = pd.read_csv('total.csv')\n",
        "\n",
        "    # ë°ì´í„° ì „ì²˜ë¦¬\n",
        "    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])\n",
        "\n",
        "    # ì˜¤ì°¨ë²”ìœ„ ê³„ì‚°\n",
        "    df['ì˜ˆì¸¡í™˜ìœ¨_ìµœì†Œ'] = np.round(df['ì˜ˆì¸¡í™˜ìœ¨'] - 1.96 * np.std(df['ì˜ˆì¸¡í™˜ìœ¨']), 2)\n",
        "    df['ì˜ˆì¸¡í™˜ìœ¨_ìµœëŒ€'] = np.round(df['ì˜ˆì¸¡í™˜ìœ¨'] + 1.96 * np.std(df['ì˜ˆì¸¡í™˜ìœ¨']), 2)\n",
        "\n",
        "    # ì‹¤ì œ í™˜ìœ¨ ë°ì´í„°ê°€ ìˆëŠ” ë§ˆì§€ë§‰ ë‚ ì§œ ì°¾ê¸°\n",
        "    last_actual_date = df.dropna(subset=['ì‹¤ì œí™˜ìœ¨'])['ë‚ ì§œ'].max()\n",
        "\n",
        "    # ì‹¤ì œ í™˜ìœ¨ ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œê¹Œì§€ë§Œ í•„í„°ë§\n",
        "    df_filtered = df[df['ë‚ ì§œ'] <= last_actual_date]\n",
        "\n",
        "    # 2023ë…„ 1ì›” 1ì¼ ì´í›„ ë°ì´í„° í•„í„°ë§\n",
        "    df_filtered = df_filtered[df_filtered['ë‚ ì§œ'] >= '2015-01-01']\n",
        "\n",
        "    # ì œëª©\n",
        "    st.title('ì˜ˆì¸¡ í™˜ìœ¨ ì •í™•ë„ ê·¸ë˜í”„')\n",
        "\n",
        "    # ê·¸ë˜í”„ ìƒì„±\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # ì‹¤ì œ í™˜ìœ¨ ë°ì´í„° ì¶”ê°€\n",
        "    fig.add_trace(go.Scatter(x=df_filtered['ë‚ ì§œ'],y=df_filtered['ì‹¤ì œí™˜ìœ¨'],mode='lines',name='ì‹¤ì œ í™˜ìœ¨',line=dict(color='red'),hovertemplate='ì‹¤ì œí™˜ìœ¨:%{y}<extra></extra>'))\n",
        "\n",
        "    # ì˜ˆì¸¡ í™˜ìœ¨ ë°ì´í„° ì¶”ê°€\n",
        "    fig.add_trace(go.Scatter(x=df_filtered['ë‚ ì§œ'],y=df_filtered['ì˜ˆì¸¡í™˜ìœ¨'],mode='lines',name='ì˜ˆì¸¡ í™˜ìœ¨',line=dict(color='green'),hovertemplate='ì˜ˆì¸¡í™˜ìœ¨:%{y}<extra></extra>'))\n",
        "\n",
        "    # ì˜¤ì°¨ë²”ìœ„ ì¶”ê°€\n",
        "    fig.add_trace(go.Scatter(x=df_filtered['ë‚ ì§œ'].tolist() + df_filtered['ë‚ ì§œ'][::-1].tolist(),y=df_filtered['ì˜ˆì¸¡í™˜ìœ¨_ìµœëŒ€'].tolist() + df_filtered['ì˜ˆì¸¡í™˜ìœ¨_ìµœì†Œ'][::-1].tolist(),fill='toself',fillcolor='rgba(0,100,80,0.2)',line_color='rgba(255,255,255,0)',hoverinfo=\"skip\",showlegend=False))\n",
        "\n",
        "    # ê·¸ë˜í”„ ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
        "    fig.update_layout(xaxis_title='ë‚ ì§œ',yaxis_title='í™˜ìœ¨',xaxis=dict(tickformat='%Y-%m-%d'), hovermode=\"x unified\", hoverlabel_bgcolor=\"white\",hoverlabel_font_size=12,hoverlabel_font_family=\"Rockwell\")\n",
        "\n",
        "    # ê·¸ë˜í”„ í‘œì‹œ\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    multi = '''ì €í¬ í”„ë¡œì íŠ¸ì—ì„œëŠ” 2019ë…„ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ë‹¤ì–‘í•œ ê¸ˆìœµ ë° ê²½ì œ ì§€í‘œë¥¼ í™œìš©í•˜ì—¬ LSTM(Long Short-Term Memory) ëª¨ë¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.\n",
        "    ë°ì´í„°ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤\n",
        "    <br>- ì£¼ìš” í™˜ìœ¨: EUR/KRW, GBP/KRW, JPY/KRW, EUR/USD, GBP/USD, JPY/USD\n",
        "    <br>- ì£¼ìš” ì£¼ì‹ ì§€ìˆ˜: ë‹¤ìš°ì¡´ìŠ¤, S&P 500, ë‚˜ìŠ¤ë‹¥, FTSE, DAX, CAC, Nikkei\n",
        "    <br>- ê¸°íƒ€ ì§€í‘œ: ë¯¸êµ­ ë‹¬ëŸ¬ ì§€ìˆ˜, ë¯¸êµ­ êµ­ì±„ ê¸ˆë¦¬(6ê°œì›”, 1ë…„, 3ë…„, 5ë…„, 10ë…„), ê¸ˆ, ì€, ì²œì—°ê°€ìŠ¤, WTI, KOSPI ì§€ìˆ˜\n",
        "\n",
        "    <br>LSTM ëª¨ë¸ì€ ê¸°ì¡´ì˜ ìˆœí™˜ ì‹ ê²½ë§(RNN)ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤. RNNì€ ë°ì´í„°ì˜ ìˆœì„œë¥¼ ê³ ë ¤í•˜ì—¬ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ì§€ë§Œ, ì¥ê¸°ì ì¸ ì˜ì¡´ì„±ì„ ë‹¤ë£¨ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆì—ˆê³ , ê·¸ë¡œ ì¸í•´ ê¸´ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì •í™•í•œ ì˜ˆì¸¡ì´ ì–´ë ¤ì› ìŠµë‹ˆë‹¤. LSTMì€ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ ëª¨ë¸ë¡œ, ì¥ê¸°ì ì¸ íŒ¨í„´ì„ ê¸°ì–µí•˜ê³ , ì¤‘ìš”í•œ ì •ë³´ëŠ” ìœ ì§€í•˜ë©° ë¶ˆí•„ìš”í•œ ì •ë³´ëŠ” ìŠì–´ë²„ë¦¬ëŠ” ëŠ¥ë ¥ì´ íƒì›”í•©ë‹ˆë‹¤.\n",
        "    <br>ì €í¬ í™˜ìœ¨ ì˜ˆì¸¡ ëª¨ë¸ì€ ì´ëŸ¬í•œ LSTMì˜ ì¥ì  ë•ë¶„ì— 2019ë…„ë„ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ì¥ê¸°ê°„ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    <br>ì‹¤ì œë¡œ, ì˜ˆì¸¡ê°’ì´ ì‹¤ì œê°’ê³¼ ê±°ì˜ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ ê·¸ë˜í”„ë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” LSTM ëª¨ë¸ì˜ ê°•ë ¥í•œ ì¥ê¸° ê¸°ì–µ ëŠ¥ë ¥ ë•ë¶„ì— ê°€ëŠ¥í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n",
        "    <br>ì´ëŸ¬í•œ ì •ë°€í•œ ì˜ˆì¸¡ì€ ê³ ê°ë“¤ì—ê²Œ ë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ì‹¤ì œ ê¸ˆìœµ ì‹œì¥ì˜ ë³€ë™ì„±ì„ ë” ì˜ ì´í•´í•˜ê³  ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "    <br>**<span style=\"font-size: 0.8em;\">ë³¸ í˜ì´ì§€ì—ì„œ ì œê³µë˜ëŠ” ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •ë³´ì˜ ì •í™•ì„±, ì™„ì „ì„±, ì‹ ë¢°ì„±ì— ëŒ€í•´ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "    ì •ë³´ì˜ ì˜¤íƒ€ë‚˜ ë°œí–‰ ì§€ì²´ ë“±ìœ¼ë¡œ ì¸í•´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì–´ë– í•œ ì†í•´ì— ëŒ€í•´ì„œë„ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  íŒë‹¨ê³¼ ê²°ì •ì€ ë³¸ì¸ì˜ ëª«ì´ë©°, ì´ì— ëŒ€í•œ ì±…ì„ì€ ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤.**'''\n",
        "\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        <style>\n",
        "        .highlight-text {\n",
        "            background-color: #5c595a;\n",
        "            color: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            border: 2px solid #fff;\n",
        "            font-family: 'Arial', sans-serif;\n",
        "            line-height: 1.6;\n",
        "        }\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <div class=\"highlight-text\">\n",
        "            {multi}\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )"
      ],
      "metadata": {
        "id": "QniGvqkwlnIb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}